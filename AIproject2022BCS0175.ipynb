{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3z6M-dQCwUo",
        "outputId": "1bec5202-aad1-46c4-89d5-2a4e873c2875"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from matplotlib import style\n",
        "plt.style.use('ggplot')\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDB dataset into a pandas DataFrame\n",
        "df = pd.read_csv('IMDB Dataset.csv')\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p2jTzvu7Db-m",
        "outputId": "c40a53fa-8b5b-4e6f-da29-fc72f4b93055"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shape (number of rows and columns) of the DataFrame\n",
        "df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uJmLPxDGOrE",
        "outputId": "714649d7-fc8c-4929-e50c-114f78f69494"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about the DataFrame, including data types and missing values\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eSZwbeqvzWq",
        "outputId": "7b3cb821-ba85-4e0d-b00e-1ba2162b95b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot to visualize the distribution of positive and negative sentiments\n",
        "sns.countplot(x='sentiment', data=df)\n",
        "plt.title(\"Positive - Negative Ratio Graph\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "LboYJVkuvzmd",
        "outputId": "652413ad-b49b-40bf-f151-977f5e8df54a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 5 reviews and their corresponding sentiments\n",
        "for i in range(5):\n",
        "    print(\"Review: \", [i])\n",
        "    print(df['review'].iloc[i], \"\\n\")\n",
        "    print(\"Sentiment: \", df['sentiment'].iloc[i], \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeW57Qjfvzum",
        "outputId": "70981c6a-a476-431a-fe77-b4fa0cee9664"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to count the number of words in a text\n",
        "def no_of_words(text):\n",
        "    words= text.split()\n",
        "    word_count = len(words)\n",
        "    return word_count"
      ],
      "metadata": {
        "id": "gfJC417ovzxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the no_of_words function to create a new column 'word count'\n",
        "df['word count'] = df['review'].apply(no_of_words)"
      ],
      "metadata": {
        "id": "ymbpLhSVvz0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame with the new 'word count' column\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ssk5gG93vz8s",
        "outputId": "4d0f6652-fbc1-4f42-a400-f74979304455"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create histograms to visualize the distribution of word counts for positive and negative reviews\n",
        "fig, ax = plt.subplots(1,2, figsize=(10,6))\n",
        "ax[0].hist(df[df['sentiment'] == 'positive']['word count'], label='Positive', color='blue', rwidth=0.9);\n",
        "ax[0].legend(loc='upper right');\n",
        "ax[1].hist(df[df['sentiment'] == 'negative']['word count'], label='Negative', color='red', rwidth=0.9);\n",
        "ax[1].legend(loc='upper right');\n",
        "fig.suptitle(\"Number of words in review\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "bsfTzsm_v0DV",
        "outputId": "ef2cf1e1-c8f2-40c2-fb01-87e2ed103136"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace sentiment labels with numerical values (1 for positive, 0 for negative)\n",
        "df['sentiment'] = df['sentiment'].replace({\"positive\": 1, \"negative\": 0})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SEBZNd41v0M3",
        "outputId": "5924ba1b-b4e6-4a33-df0b-057ac0c573a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame with the updated sentiment values\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gKskKb3kv0RX",
        "outputId": "f1481033-8977-49d2-f288-a1dbff17acf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to preprocess text data\n",
        "def data_processing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('<br />', '', text)\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@w+|\\#','', text)\n",
        "    text = re.sub(r'[^\\w\\s]','', text)\n",
        "    text_tokens = word_tokenize(text)\n",
        "    filtered_text = [w for w in text_tokens if not w in stop_words]\n",
        "    return \" \".join(filtered_text)"
      ],
      "metadata": {
        "id": "9gsuTN5Wv0U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing NLTK library and downloading the 'punkt' tokenizer model for text processing\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Applying a data processing function to the 'review' column\n",
        "df['review'] = df['review'].apply(data_processing)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHesT6rGv0Y3",
        "outputId": "d67c92cb-30e7-4e1b-849a-965655b8f829"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking and displaying the count of duplicate entries in the dataset\n",
        "duplicated_count = df.duplicated().sum()\n",
        "print(\"Number of duplicate entries: \", duplicated_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5YeTXd9v0e1",
        "outputId": "c6a8a905-b4c8-4910-a296-c8dbb7f2ed6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing duplicate rows based on the 'review' column\n",
        "df = df.drop_duplicates('review')"
      ],
      "metadata": {
        "id": "XGXoG-mVv0h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming words in the 'review' column to normalize text\n",
        "stemmer = PorterStemmer()\n",
        "def stemming(data):\n",
        "    text = [stemmer.stem(word) for word in data.split()]\n",
        "    return \" \".join(text)\n"
      ],
      "metadata": {
        "id": "pX41mgKqv0nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(lambda x: stemming(x))\n"
      ],
      "metadata": {
        "id": "Is0PJNVDv0qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a 'word count' column and displaying the first few rows of the updated DataFrame\n",
        "df['word count'] = df['review'].apply(no_of_words)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vEYD2O8Ev0s9",
        "outputId": "910d0c56-bc2a-4cbb-d79a-69120ffb3ad1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Filtering and displaying reviews with a positive sentiment (sentiment = 1)\n",
        "pos_reviews = df[df.sentiment ==1]\n",
        "pos_reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "936g5hkR4SS8",
        "outputId": "91b29b07-2973-4d39-c007-d0c44afe23e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating and displaying a word cloud for the most frequent words in positive reviews\n",
        "text = ' '.join([word for word in pos_reviews['review']])\n",
        "plt.figure(figsize=(20,15), facecolor='None')\n",
        "wordcloud = WordCloud(max_words=100, width=1600, height=800, collocations=False).generate(text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title('Most frequent words in positive reviews', fontsize = 19)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "ewIl2sJ74ScC",
        "outputId": "07e0fd12-aae7-4eaa-bc05-b09f8680d173"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting and displaying the top 15 most common words in positive reviews\n",
        "from collections import Counter\n",
        "count = Counter()\n",
        "for text in pos_reviews['review'].values:\n",
        "    for word in text.split():\n",
        "        count[word] +=1\n",
        "count.most_common(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKs9YsNM4Sfp",
        "outputId": "6a5cde54-a01c-4120-9ccf-dd07834c766e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and displaying a DataFrame with the most common words and their counts in positive reviews\n",
        "pos_words = pd.DataFrame(count.most_common(15))\n",
        "pos_words.columns = ['word', 'count']\n",
        "pos_words.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8WcZtvx24Skm",
        "outputId": "031f95fb-7877-42c1-8b26-aca4b76ff317"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a bar chart of common words in positive reviews\n",
        "px.bar(pos_words, x='count', y='word', title='Common words in positive reviews', color='word')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "HNw_aWgu4SsG",
        "outputId": "b18bac90-6895-4cc7-ab92-0757be8e13b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering and displaying reviews with a negative sentiment (sentiment = 0)\n",
        "neg_reviews = df[df.sentiment == 0]\n",
        "neg_reviews.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Y17fhEoU4S15",
        "outputId": "3434422a-1af9-452c-ae5a-8b52b8056b2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating and displaying a word cloud for the most frequent words in negative reviews\n",
        "text = ' '.join([word for word in neg_reviews['review']])\n",
        "plt.figure(figsize=(20,15), facecolor='None')\n",
        "wordcloud = WordCloud(max_words=100, width=1600, height=800, collocations=False).generate(text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title('Most frequent words in negative reviews', fontsize = 19)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "D9-Am0Wr8bIe",
        "outputId": "a42522ec-c63f-4334-ee8f-73b2a1056a8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting and displaying the top 15 most common words in negative reviews\n",
        "count = Counter()\n",
        "for text in neg_reviews['review'].values:\n",
        "    for word in text.split():\n",
        "        count[word] += 1\n",
        "count.most_common(15)"
      ],
      "metadata": {
        "id": "Plokj5wh8bQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and displaying a DataFrame with the most common words and their counts in negative reviews\n",
        "neg_words = pd.DataFrame(count.most_common(15))\n",
        "neg_words.columns = ['word', 'count']\n",
        "neg_words.head()"
      ],
      "metadata": {
        "id": "cFMzo3208bW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a bar chart of common words in negative reviews\n",
        "px.bar(neg_words, x='count', y='word', title='Common words in negative reviews', color='word')"
      ],
      "metadata": {
        "id": "lEnv1a9r8bdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['review']\n",
        "Y = df['sentiment']"
      ],
      "metadata": {
        "id": "2rXS7tLw8bk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming review text into TF-IDF features\n",
        "vect = TfidfVectorizer()\n",
        "X = vect.fit_transform(df['review'])"
      ],
      "metadata": {
        "id": "P_TxrGFd8br8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into training and testing sets(70% training, 30% testing)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "tEFAQthU8bx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of x_train: \", (x_train.shape))\n",
        "print(\"Size of y_train: \", (y_train.shape))\n",
        "print(\"Size of x_test: \", (x_test.shape))\n",
        "print(\"Size of y_test: \", (y_test.shape))"
      ],
      "metadata": {
        "id": "R4K1hfp_v03f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limiting training and testing data to a subset for faster model training, and safe running on a system\n",
        "# We can increase the size gradually to improve results, provided we have an efficient CPU/GPU for running it\n",
        "x_train = x_train[:2000]\n",
        "y_train = y_train[:2000]\n",
        "x_test = x_test[:500]\n",
        "y_test = y_test[:500]"
      ],
      "metadata": {
        "id": "JS4NXjyV_-Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of x_train: \", (x_train.shape))\n",
        "print(\"Size of y_train: \", (y_train.shape))\n",
        "print(\"Size of x_test: \", (x_test.shape))\n",
        "print(\"Size of y_test: \", (y_test.shape))"
      ],
      "metadata": {
        "id": "LdEObw4S_-ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting sparse matrices to arrays\n",
        "x_train = x_train.toarray()\n",
        "x_test = x_test.toarray()"
      ],
      "metadata": {
        "id": "W95Bz95__-fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Dropout\n",
        "\n",
        "# Setting input dimension for the neural network model\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "# Defining a simple neural network model with one hidden layer for sentiment analysis\n",
        "model = Sequential([\n",
        "    Input(shape=(input_dim,)),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# We can also run the below code to compile the model using the same data but with a different activation function and more layers. After running both, we can choose the better one for our model\n",
        "'''\n",
        "model = Sequential([\n",
        "    Input(shape=(input_dim,)),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=16, activation='swish'),\n",
        "    Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "'''\n"
      ],
      "metadata": {
        "id": "WWo0rzBs_-oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying which optimizer to use\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# We can also run the below code to compile the model using the same data but with a different optimizer. After running both, we can choose the better one for our model based on the accuracy\n",
        "'''\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "'''"
      ],
      "metadata": {
        "id": "PeWmOE96_-v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying the essential information like number of epochs for running the Neural Network\n",
        "history = model.fit(x_train, y_train, batch_size=10, epochs=15)\n",
        "\n",
        "# We can try with different batch sizes and epochs and see which one gives a better model in terms of accuracy. Alternative is given below\n",
        "'''\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=20)\n",
        "'''"
      ],
      "metadata": {
        "id": "9BkXTRJgJInZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "kUfhkmUVJItB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing the accuracy and error values of the model using the particular optimizer and activation function\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "xgGHPtCCJI38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === FINAL RESULTS SUMMARY ===\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions on test set\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "print('=' * 60)\n",
        "print('SENTIMENT ANALYSIS MODEL - FINAL RESULTS')\n",
        "print('=' * 60)\n",
        "print(f'\\nTest Loss:     {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_acc:.4f} ({test_acc*100:.1f}%)')\n",
        "print(f'\\nTotal test samples: {len(y_test)}')\n",
        "print(f'Correct predictions: {(predicted_labels == y_test.values).sum()}')\n",
        "print(f'Wrong predictions:   {(predicted_labels != y_test.values).sum()}')\n",
        "print('\\n' + '=' * 60)\n",
        "print('SAMPLE PREDICTIONS')\n",
        "print('=' * 60)\n",
        "for i in range(10):\n",
        "    actual = 'Positive' if y_test.values[i] == 1 else 'Negative'\n",
        "    predicted = 'Positive' if predicted_labels[i] == 1 else 'Negative'\n",
        "    status = '✓' if y_test.values[i] == predicted_labels[i] else '✗'\n",
        "    print(f'  [{status}] Sample {i+1}: Actual={actual:>8s}, Predicted={predicted:>8s}')\n",
        "print('=' * 60)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === FINAL RESULTS SUMMARY ===\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions on test set\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "print('=' * 60)\n",
        "print('SENTIMENT ANALYSIS MODEL - FINAL RESULTS')\n",
        "print('=' * 60)\n",
        "print(f'\\nTest Loss:     {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_acc:.4f} ({test_acc*100:.1f}%)')\n",
        "print(f'\\nTotal test samples: {len(y_test)}')\n",
        "print(f'Correct predictions: {(predicted_labels == y_test.values).sum()}')\n",
        "print(f'Wrong predictions:   {(predicted_labels != y_test.values).sum()}')\n",
        "print('\\n' + '=' * 60)\n",
        "print('SAMPLE PREDICTIONS')\n",
        "print('=' * 60)\n",
        "for i in range(10):\n",
        "    actual = 'Positive' if y_test.values[i] == 1 else 'Negative'\n",
        "    predicted = 'Positive' if predicted_labels[i] == 1 else 'Negative'\n",
        "    status = 'OK' if y_test.values[i] == predicted_labels[i] else 'WRONG'\n",
        "    print(f'  [{status}] Sample {i+1}: Actual={actual:>8s}, Predicted={predicted:>8s}')\n",
        "print('=' * 60)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}